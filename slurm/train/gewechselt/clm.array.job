#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH --job-name=DEB_G_TRAIN
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=120:00:00
#SBATCH --mem-per-gpu=48G
#SBATCH --array=1-20%4
#SBATCH --output=slurm/outputs/train/arrays/clm_gewechselt_%A_%a.out

source "./slurm/.secrets"

module purge
module load 2022
module load Miniconda3/4.12.0

source activate claficle

HPARAMS_FILE=slurm/train/gewechselt/clm.array.txt

srun python -u claficle/run/train.py debug=true \
  model.name=gewechselt \
  model.pl_checkpoint=gpt2-large_Gewechselt_fr.ckpt \
  tokenizer_name=fr_gewechselt \
  trainer.progress_bar=true
